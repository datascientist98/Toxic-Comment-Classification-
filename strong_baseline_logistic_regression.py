# -*- coding: utf-8 -*-
"""Strong_Baseline_Logistic_Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pxZkmuCbnAqSLWImwjE-ZJzPLyHV9uux
"""

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import cross_val_score
import sys


def clean(str):

  return str.replace('\n', ' ').replace('\t', ' ')
  
  
def replace_invalid_chars(data):

  cleaning = np.vectorize(clean)
  return cleaning(data['comment_text'])
  
  
if __name__ == '__main__':

    try: 
        df_train = pd.read_csv(sys.argv[1])
        df_val = pd.read_csv(sys.argv[2])
        df_test = pd.read_csv(sys.argv[3])
        
        test_label_output_path = sys.argv[4]
    
    except Exception as ex:
        print(f'Missing argument(s). {ex}')
        sys.exit(1)


    df_train['comment_text'] = replace_invalid_chars(df_train)
    df_val['comment_text'] = replace_invalid_chars(df_val)
    df_test['comment_text'] = replace_invalid_chars(df_test)

    df_train.drop(df_train[(df_train['toxic'] == -1) | (df_train['severe_toxic'] == -1) | (df_train['obscene'] ==-1) | (df_train['threat'] == -1) | (df_train['insult'] == -1) | (df_train['identity_hate'] == -1)].index, inplace = True)

    df_val.drop(df_val[(df_val['toxic'] == -1) | (df_val['severe_toxic'] == -1) | (df_val['obscene'] ==-1) | (df_val['threat'] == -1) | (df_val['insult'] == -1) | (df_val['identity_hate'] == -1)].index, inplace = True)

    df_test.drop(df_test[(df_test['toxic'] == -1) | (df_test['severe_toxic'] == -1) | (df_test['obscene'] ==-1) | (df_test['threat'] == -1) | (df_test['insult'] == -1) | (df_test['identity_hate'] == -1)].index, inplace = True)

    df_train.head()

    df_val.head()

    df_test.head()

    lens = df_train.comment_text.str.len()
    lens.mean(), lens.std(), lens.max()

    df_train['comment_text'].isna().sum()

    df_val['comment_text'].isna().sum()

    df_test['comment_text'].isna().sum()

    labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

    df_train_text = df_train['comment_text']
    df_val_text = df_val['comment_text']
    df_test_text = df_test['comment_text']
    #df_full_text = pd.concat([df_train_text, df_test_text])

    word_vectorizer = TfidfVectorizer(
        sublinear_tf=True,
        strip_accents='unicode',
        analyzer='word',
        token_pattern=r'\w{1,}',
        stop_words='english',
        ngram_range=(1, 1),
        max_features=5000)

    word_vectorizer.fit(df_train_text)

    train_features = word_vectorizer.transform(df_train_text)
    val_features = word_vectorizer.transform(df_val_text)
    test_features = word_vectorizer.transform(df_test_text)

    scores = []
    val_output = pd.DataFrame.from_dict({'id': df_val['id']})
    test_output = pd.DataFrame.from_dict({'id': df_test['id']})
    for label in labels:
        train_target = df_train[label]
        clf = LogisticRegression(C=0.1, solver='sag')
        cv_score = np.mean(cross_val_score(clf, train_features, train_target, cv=3))
        scores.append(cv_score)
        print('CV score for class {} is {}'.format(label, cv_score))

        clf.fit(train_features, train_target)
        #output[label] = clf.predict_proba(val_features)[:, 1]
        val_output[label] = clf.predict(val_features)
        test_output[label] = clf.predict(test_features)
    print('Total CV score is {}'.format(np.mean(scores)))

    # val_output.to_csv('val_output.csv', index=False)

    # test_output.to_csv('test_output.csv', index=False)
    test_output.to_csv(test_label_output_path, index=False)

    # print("For validation data -")
    # for label in labels:
      # fs_val = f1_score(val_output[label], df_val[label])
      # print("f1_score of label",label,"is: ",fs_val)
    # print("For test data -")
    # for label in labels:
      # fs_test = f1_score(test_output[label], df_test[label])
      # print("f1_score of label",label,"is: ",fs_test)

    
    # print("For validation data -")
    # for label in labels:
      # cm_val = confusion_matrix(df_val[label], val_output[label])
      # print(label,'\n',cm_val)
    # print("For test data -")
    # for label in labels:
      # cm_test = confusion_matrix(df_test[label], test_output[label])
      # print(label, '\n', cm_test)

